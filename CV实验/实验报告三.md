## 1. 训练集和测试集构成
---
### 1.1 数据加载

1. 从MNIST数据集加载原始的训练集和测试集，并将其进行正态化数据预处理
2. 从原始的训练集和测试集中随机选取10%数据作为子集
3. 将子集包装成SiameseDataset的形式
4. 将SiameseDataset加载至DataLoader，训练集batch大小为64，测试集batch大小为1，并使用shuffle打乱

### 1.2 SiameseDataset定义

- 自定义的数据集需要重写`__init__`，`__len__`和`__getitem__`方法
- `__init__`：使用传入的数据集和标签来初始化，同时创建一个枚举列表用于初始化indices属性
- `__len__`：返回数据集长度即可
- `__getitem__`：根据index返回元素。根据实验要求，应该返回两张图片，以及表示这两张图片是否相同的一个张量。在返回元素时，为确保数据集中包含了一定比例的相同类别和不同类别的样本，我们以50%的概率选择同一类别的图像。同时在选取时注意不选取两张相同的图像。

## 2.神经网络架构
---
- 神经网络架构的设计使用了孪生神经网络的设计思想
	- 孪生神经网络有两个输入（Input1 and Input2）,将两个输入feed进入两个神经网络（Network1 and Network2），这两个神经网络分别将输入映射到新的空间，形成输入在新的空间中的表示。通过Loss的计算，评价两个输入的相似度。
- 所耦合的神经网络选取的是实验二中所构建的ResNet架构
- 通过forward_one返回一个网络的output，再通过forward返回两个output的欧氏距离（即相似度），将结果再经过一层全连接层输出进行分类

## 3.损失
---
### 3.1 每一轮mini-batch的损失

- 输出内容过多，截取部分展示：![[Pasted image 20231226164508.png]]

### 3.2 每一轮epoch的损失

- 如图所示：![[Pasted image 20231226164807.png]]
- 经过10轮epoch之后损失减少至0.065611

## 4.准确率
---
### 4.1 在训练集上的准确率

- 如图所示：![[Pasted image 20231226165001.png]]

### 4.2 在测试集上的准确率

- 如图所示：![[Pasted image 20231226165041.png]]

## 5.总结
---
- 在10轮epoch之后，使用ResNet耦合的孪生神经网络的准确率能够达到96%以上。